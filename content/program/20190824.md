---
title: "初談Deep Learning(3) - Training"
date: 2019-08-24T11:40:11+08:00
publishdate: 2019-08-24T11:40:11+08:00
tags: ["deep learning"]
comments: false
---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

當我們建立模型後，就必續進行訓練。

訓練準備前，除了模型的設計以外，資料集的準備也是非常重要。

<!--more-->


### 訓練的過程應該分為兩個步驟

- 保證能學好現有的數據
    - 這往往需要調整一些超參數(Hyper-Parameters)，如果學得不好，稱作Under-Fitting
- 檢驗新數據的性能，這個稱為泛化能力
    - 如果在舊數據上性能好，新數據上性能差，說明泛化能力差，稱為Over-Fitting
    - 如果新數據上性能也好，則泛化能力強，這是我們追求的目標。

<br>

### 傳統嚴格的作法

- 會將資料分為三部分
    - 訓練集Training Set : 訓練網絡
    - 驗證集Validation Set : 調整網絡的超參數
    - 測試集Testing Set : 檢測與預測網絡對於未來新數據的效果
    
- 傳統Machine Learning方法會取80% 10% 10%
- 但Deep Learning往往需要更大的訓練集，所以通常會90% 5% 5%甚至更多

<br>

### 典型的訓練過程

1. 選定一組超參數，用訓練集訓練網絡。
2. 調整超參數，直到可在訓練集上獲得較好的效果。
3. 在驗證集上運行網絡，看效果如何。
4. 調整超參數，直到可在訓練集和驗證集上得到較好的效果。
5. 最後，對於超參數滿意後，在測試集上運行網絡。(但別在這個步驟調整超參數，不然就失去測試集和驗證集之間的意義了。)

<br>

### 如果想要更有說服力，可使用交叉驗證(Cross Validation)

1. 將數據分成k份
2. 初始化網絡。選取數據中的第一份做為測試集，其餘當作訓練集，得到一個結果。
3. 重新初始化網絡。選取數據中的第二份做為測試集，其餘當作訓練集，得到一個結果。
4. …(重複動作)
5. 重新初始化網絡。選取數據中的第k份做為測試集，其餘當作訓練集，得到一個結果。
6. 對所有結果取平均，即為一個更有說服力的結果。
不過，由於深度網絡的訓練往往較慢，因此交叉驗證的過程會更慢。

<br>

### Under-fitting & Over-Fitting

- Under-Fitting
    - 訓練集性能較差
    - 通常出線的原因
        - 網絡的容量(Capacity)不足
        - 網絡規模很大，但效果差的話
            - 可能是因為訓練的超參數不夠妥當，如學習速率過大或過小
            - 也有可能是數據本身問題
- Over-Fitting
    - 訓練集性能好，但是測試集或新數據性能差
    - 可在網絡中引入正規化(Regularization)，以試圖找到更穩定的參數
    - 可使用數據增強(Data Augmentation)技術，從現有的樣本生成更多的樣本，改善網絡的訓練。
- Early-Stopping
    - 如果發現在測試集的性能越訓練越差，就應該停止訓練。

<br>

### 訓練的細節 : 局部極值點、鞍點、梯度下降算法
- 局部極小值點(Local Minimum)
    - 從數學角度而言，梯度下降屬於貪心算法，對於非凸(non-convex)問題，有可能陷入局部極小值點(Local Minimum)，無法保證到達全局極小值點(Global Minimum)，這就屬於under-fitting
- 鞍點(Saddle Point)
    - 實際訓練過程中，容易造成訓練的障礙
    - 鞍點附近維度是往下，有些往上
    - 梯度下降法，最終還是會脫離鞍點，但會停留一段時間，影響訓練速度。
- 著名定理 "沒有免費午餐(No Free Lunch Theorem)"
    - 即不會有一種萬能永遠比其他優化算法更好的優化算法，一切都須由實際實驗決定。

<br>
***
